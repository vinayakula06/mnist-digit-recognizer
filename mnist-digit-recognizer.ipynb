{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n!pip install torch\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-26T14:39:16.528505Z","iopub.execute_input":"2024-10-26T14:39:16.528992Z","iopub.status.idle":"2024-10-26T14:39:30.760508Z","shell.execute_reply.started":"2024-10-26T14:39:16.528947Z","shell.execute_reply":"2024-10-26T14:39:30.759288Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:30.762679Z","iopub.execute_input":"2024-10-26T14:39:30.763361Z","iopub.status.idle":"2024-10-26T14:39:33.384983Z","shell.execute_reply.started":"2024-10-26T14:39:30.763319Z","shell.execute_reply":"2024-10-26T14:39:33.383792Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(r\"/kaggle/input/digit-recognizer/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:33.386458Z","iopub.execute_input":"2024-10-26T14:39:33.387016Z","iopub.status.idle":"2024-10-26T14:39:36.917189Z","shell.execute_reply.started":"2024-10-26T14:39:33.386975Z","shell.execute_reply":"2024-10-26T14:39:36.916197Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test=pd.read_csv(r\"/kaggle/input/digit-recognizer/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:36.918576Z","iopub.execute_input":"2024-10-26T14:39:36.919051Z","iopub.status.idle":"2024-10-26T14:39:38.977295Z","shell.execute_reply.started":"2024-10-26T14:39:36.919002Z","shell.execute_reply":"2024-10-26T14:39:38.976098Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"y_train = train['label']\ntrain.drop(columns=['label'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:38.980337Z","iopub.execute_input":"2024-10-26T14:39:38.980803Z","iopub.status.idle":"2024-10-26T14:39:39.068143Z","shell.execute_reply.started":"2024-10-26T14:39:38.980755Z","shell.execute_reply":"2024-10-26T14:39:39.066807Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as transforms\ntransform = transforms.Compose([\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:39.069804Z","iopub.execute_input":"2024-10-26T14:39:39.070187Z","iopub.status.idle":"2024-10-26T14:39:40.107382Z","shell.execute_reply.started":"2024-10-26T14:39:39.070148Z","shell.execute_reply":"2024-10-26T14:39:40.106180Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_CV, y_train, y_CV = train_test_split(train, y_train, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:40.109112Z","iopub.execute_input":"2024-10-26T14:39:40.109860Z","iopub.status.idle":"2024-10-26T14:39:40.427058Z","shell.execute_reply.started":"2024-10-26T14:39:40.109790Z","shell.execute_reply":"2024-10-26T14:39:40.425943Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, data, label=None, transform=None):\n        self.data = torch.tensor(data.values, dtype=torch.float32).reshape(-1, 1, 28, 28)\n        if label is not None:\n            self.labels = torch.tensor(label.values, dtype=torch.int64)\n        else:\n            self.labels = None\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image = self.data[idx]\n        if self.transform:\n            image = self.transform(image)\n        if self.labels is not None:\n            label = self.labels[idx]\n            return image, label\n        return image\n\n# Example transformations\ntransform = transforms.Compose([\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Assuming 'X_train', 'X_CV', 'y_train', 'y_CV', and 'test' are defined DataFrames\ntrain_data = CustomImageDataset(data=X_train, label=y_train, transform=transform)\nvalidation_data = CustomImageDataset(data=X_CV, label=y_CV, transform=transform)\ntest_data = CustomImageDataset(data=test, transform=transform)  # No labels for test data\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nvalidation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:40.428149Z","iopub.execute_input":"2024-10-26T14:39:40.428490Z","iopub.status.idle":"2024-10-26T14:39:40.588803Z","shell.execute_reply.started":"2024-10-26T14:39:40.428453Z","shell.execute_reply":"2024-10-26T14:39:40.586963Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super(LeNet5, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = torch.tanh(self.conv1(x))\n        x = nn.functional.avg_pool2d(x, 2)\n        x = torch.tanh(self.conv2(x))\n        x = nn.functional.avg_pool2d(x, 2)\n        x = x.view(-1, 16 * 4 * 4)\n        x = torch.tanh(self.fc1(x))\n        x = torch.tanh(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nmodel = LeNet5()\nerror = nn.CrossEntropyLoss()\n\n# SGD Optimizer\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:44.289483Z","iopub.execute_input":"2024-10-26T14:39:44.290742Z","iopub.status.idle":"2024-10-26T14:39:44.317892Z","shell.execute_reply.started":"2024-10-26T14:39:44.290682Z","shell.execute_reply":"2024-10-26T14:39:44.316486Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n# Check for CUDA (GPU) availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training variables\ncount = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\n\n# Specify the number of epochs\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        \n        # Move tensors to the configured device\n        data, target = data.to(device), target.to(device)\n        \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(data)\n        \n        # Calculate loss\n        loss = error(outputs, target)\n        \n        # Backpropagation\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        if count % 50 == 0:\n            # Calculate Accuracy on validation data\n            correct = 0\n            total = 0\n            with torch.no_grad():\n                for val_images, val_labels in validation_loader:\n                    val_images, val_labels = val_images.to(device), val_labels.to(device)\n                    outputs = model(val_images)\n                    predicted = torch.max(outputs.data, 1)[1]\n                    total += len(val_labels)\n                    correct += (predicted == val_labels).sum().item()\n                \n            accuracy = 100 * correct / float(total)\n            \n            # Store loss and iteration values\n            loss_list.append(loss.item())\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n            \n            if count % 500 == 0:\n                # Print Loss and Accuracy\n                print(f\"Iteration: {count}  Loss: {loss.item()}  Accuracy: {accuracy}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:39:46.468177Z","iopub.execute_input":"2024-10-26T14:39:46.468585Z","iopub.status.idle":"2024-10-26T14:43:40.150662Z","shell.execute_reply.started":"2024-10-26T14:39:46.468548Z","shell.execute_reply":"2024-10-26T14:43:40.149533Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Iteration: 500  Loss: 0.2460005134344101  Accuracy: 93.60714285714286%\nIteration: 1000  Loss: 0.123175710439682  Accuracy: 95.80952380952381%\nIteration: 1500  Loss: 0.09953920543193817  Accuracy: 96.27380952380952%\nIteration: 2000  Loss: 0.16037574410438538  Accuracy: 97.26190476190476%\nIteration: 2500  Loss: 0.021714232861995697  Accuracy: 97.71428571428571%\nIteration: 3000  Loss: 0.04945326969027519  Accuracy: 97.8452380952381%\nIteration: 3500  Loss: 0.07468422502279282  Accuracy: 97.4047619047619%\nIteration: 4000  Loss: 0.018424050882458687  Accuracy: 98.0952380952381%\nIteration: 4500  Loss: 0.023861734196543694  Accuracy: 98.22619047619048%\nIteration: 5000  Loss: 0.046904101967811584  Accuracy: 98.21428571428571%\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\ntest_outputs = []\n\nwith torch.no_grad():\n    for data in test_loader:\n        if data is not None:\n            data = data.to(device)\n            outputs = model(data)\n            _, predicted = torch.max(outputs, 1)\n            test_outputs.extend(predicted.cpu().numpy())\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:44:36.717573Z","iopub.execute_input":"2024-10-26T14:44:36.718608Z","iopub.status.idle":"2024-10-26T14:44:40.971872Z","shell.execute_reply.started":"2024-10-26T14:44:36.718558Z","shell.execute_reply":"2024-10-26T14:44:40.970663Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_predictions = pd.DataFrame(test_outputs, columns=['Label'])\ntest_predictions['ImageId'] = test_predictions.index + 1\ntest_predictions = test_predictions[['ImageId', 'Label']]","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:44:49.108813Z","iopub.execute_input":"2024-10-26T14:44:49.109745Z","iopub.status.idle":"2024-10-26T14:44:49.227988Z","shell.execute_reply.started":"2024-10-26T14:44:49.109699Z","shell.execute_reply":"2024-10-26T14:44:49.226935Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_predictions.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T14:45:18.589839Z","iopub.execute_input":"2024-10-26T14:45:18.590852Z","iopub.status.idle":"2024-10-26T14:45:18.644240Z","shell.execute_reply.started":"2024-10-26T14:45:18.590788Z","shell.execute_reply":"2024-10-26T14:45:18.642959Z"},"trusted":true},"execution_count":15,"outputs":[]}]}